{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f92060a-2583-4067-a4ae-2912f434a564",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T11:45:05.384466Z",
     "iopub.status.busy": "2021-10-21T11:45:05.384466Z",
     "iopub.status.idle": "2021-10-21T11:45:07.239278Z",
     "shell.execute_reply": "2021-10-21T11:45:07.239278Z",
     "shell.execute_reply.started": "2021-10-21T11:45:05.384466Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dlib\n",
    "\n",
    "print(dlib.cuda.get_num_devices())\n",
    "\n",
    "import face_recognition\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9da83217-fb3c-461a-ade4-1bcaa3fa22aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T12:24:37.850291Z",
     "iopub.status.busy": "2021-10-19T12:24:37.850291Z",
     "iopub.status.idle": "2021-10-19T12:24:38.917375Z",
     "shell.execute_reply": "2021-10-19T12:24:38.916388Z",
     "shell.execute_reply.started": "2021-10-19T12:24:37.850291Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(554, 1221, 1016, 759)]\n"
     ]
    }
   ],
   "source": [
    "image = face_recognition.load_image_file(r'C:\\Users\\14640\\Pictures\\unknown_pictures\\WIN_20211019_20_07_41_Pro.jpg')\n",
    "face_locations = face_recognition.face_locations(image)\n",
    "\n",
    "# face_locations is now an array listing the co-ordinates of each face!\n",
    "print(face_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66da1049-5156-4904-9c4b-d32fc6db759a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T12:26:47.748131Z",
     "iopub.status.busy": "2021-10-19T12:26:47.748131Z",
     "iopub.status.idle": "2021-10-19T12:26:51.104388Z",
     "shell.execute_reply": "2021-10-19T12:26:51.104388Z",
     "shell.execute_reply.started": "2021-10-19T12:26:47.748131Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I found 1 face(s) in this photograph.\n",
      "A face is located at pixel location Top: 418, Left: 803, Bottom: 804, Right: 1188\n"
     ]
    }
   ],
   "source": [
    "# Load the jpg file into a numpy array\n",
    "image = face_recognition.load_image_file(r'C:\\Users\\14640\\Pictures\\Camera Roll\\刘青沅.jpg')\n",
    "\n",
    "# Find all the faces in the image using the default HOG-based model.\n",
    "# This method is fairly accurate, but not as accurate as the CNN model and not GPU accelerated.\n",
    "# See also: find_faces_in_picture_cnn.py\n",
    "face_locations = face_recognition.face_locations(image)\n",
    "\n",
    "print(\"I found {} face(s) in this photograph.\".format(len(face_locations)))\n",
    "\n",
    "for face_location in face_locations:\n",
    "\n",
    "    # Print the location of each face in this image\n",
    "    top, right, bottom, left = face_location\n",
    "    print(\"A face is located at pixel location Top: {}, Left: {}, Bottom: {}, Right: {}\".format(top, left, bottom, right))\n",
    "\n",
    "    # You can access the actual face itself like this:\n",
    "    face_image = image[top:bottom, left:right]\n",
    "    pil_image = Image.fromarray(face_image)\n",
    "    pil_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60c995e3-648e-4ca7-9906-0d40d5fe4bd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T12:53:26.663788Z",
     "iopub.status.busy": "2021-10-19T12:53:26.663788Z",
     "iopub.status.idle": "2021-10-19T12:55:20.087476Z",
     "shell.execute_reply": "2021-10-19T12:55:20.087476Z",
     "shell.execute_reply.started": "2021-10-19T12:53:26.663788Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# This is a demo of running face recognition on live video from your webcam. It's a little more complicated than the\n",
    "# other example, but it includes some basic performance tweaks to make things run a lot faster:\n",
    "#   1. Process each video frame at 1/4 resolution (though still display it at full resolution)\n",
    "#   2. Only detect faces in every other frame of video.\n",
    "\n",
    "# PLEASE NOTE: This example requires OpenCV (the `cv2` library) to be installed only to read from your webcam.\n",
    "# OpenCV is *not* required to use the face_recognition library. It's only required if you want to run this\n",
    "# specific demo. If you have trouble installing it, try any of the other demos that don't require it instead.\n",
    "\n",
    "# Get a reference to webcam #0 (the default one)\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "# Load a sample picture and learn how to recognize it.\n",
    "liuqingyuan_image = face_recognition.load_image_file(r\"C:\\Users\\14640\\Pictures\\known_pictures\\刘青沅.jpg\")\n",
    "liuqingyuan_face_encoding = face_recognition.face_encodings(liuqingyuan_image)[0]\n",
    "\n",
    "# # Load a second sample picture and learn how to recognize it.\n",
    "# biden_image = face_recognition.load_image_file(\"biden.jpg\")\n",
    "# biden_face_encoding = face_recognition.face_encodings(biden_image)[0]\n",
    "\n",
    "# Create arrays of known face encodings and their names\n",
    "known_face_encodings = [\n",
    "    liuqingyuan_face_encoding,\n",
    "#     biden_face_encoding\n",
    "]\n",
    "known_face_names = [\n",
    "    \"Liu Qingyuan\",\n",
    "#     \"Joe Biden\"\n",
    "]\n",
    "\n",
    "# Initialize some variables\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "process_this_frame = True\n",
    "\n",
    "while True:\n",
    "    # Grab a single frame of video\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    # Resize frame of video to 1/4 size for faster face recognition processing\n",
    "    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "\n",
    "    # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
    "    rgb_small_frame = small_frame[:, :, ::-1]\n",
    "\n",
    "    # Only process every other frame of video to save time\n",
    "    if process_this_frame:\n",
    "        # Find all the faces and face encodings in the current frame of video\n",
    "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "\n",
    "        face_names = []\n",
    "        for face_encoding in face_encodings:\n",
    "            # See if the face is a match for the known face(s)\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding, tolerance=0.4)\n",
    "            name = \"Unknown\"\n",
    "\n",
    "            # # If a match was found in known_face_encodings, just use the first one.\n",
    "            # if True in matches:\n",
    "            #     first_match_index = matches.index(True)\n",
    "            #     name = known_face_names[first_match_index]\n",
    "\n",
    "            # Or instead, use the known face with the smallest distance to the new face\n",
    "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            if matches[best_match_index]:\n",
    "                name = known_face_names[best_match_index]\n",
    "\n",
    "            face_names.append(name)\n",
    "\n",
    "    process_this_frame = not process_this_frame\n",
    "\n",
    "\n",
    "    # Display the results\n",
    "    for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "        # Scale back up face locations since the frame we detected in was scaled to 1/4 size\n",
    "        top *= 4\n",
    "        right *= 4\n",
    "        bottom *= 4\n",
    "        left *= 4\n",
    "\n",
    "        # Draw a box around the face\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "        # Draw a label with a name below the face\n",
    "        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Hit 'q' on the keyboard to quit!\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release handle to the webcam\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec24fc57-da74-4b2b-9ec9-cfae41e134d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-20T08:24:27.177571Z",
     "iopub.status.busy": "2021-10-20T08:24:27.176574Z",
     "iopub.status.idle": "2021-10-20T08:24:27.188543Z",
     "shell.execute_reply": "2021-10-20T08:24:27.187545Z",
     "shell.execute_reply.started": "2021-10-20T08:24:27.177571Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'刘青沅.jpg'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf1dd88e-1ad8-48e5-970a-30625ebe1c0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-20T08:26:15.617794Z",
     "iopub.status.busy": "2021-10-20T08:26:15.617794Z",
     "iopub.status.idle": "2021-10-20T08:26:15.635747Z",
     "shell.execute_reply": "2021-10-20T08:26:15.634748Z",
     "shell.execute_reply.started": "2021-10-20T08:26:15.617794Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'刘青沅'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.splitext('刘青沅.jpg')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86708693-24b6-47c5-af0d-ff10d24487c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-20T08:50:38.531879Z",
     "iopub.status.busy": "2021-10-20T08:50:38.530880Z",
     "iopub.status.idle": "2021-10-20T08:50:38.578938Z",
     "shell.execute_reply": "2021-10-20T08:50:38.578433Z",
     "shell.execute_reply.started": "2021-10-20T08:50:38.531879Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "known_img = face_recognition.load_image_file('C:/Users/14640/Pictures/known_pictures/路静琛.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9fe4d018-ebaf-4fc9-8db1-fcf451a3927b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-20T08:53:16.910969Z",
     "iopub.status.busy": "2021-10-20T08:53:16.909998Z",
     "iopub.status.idle": "2021-10-20T08:53:18.173836Z",
     "shell.execute_reply": "2021-10-20T08:53:18.173836Z",
     "shell.execute_reply.started": "2021-10-20T08:53:16.910969Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "known_face_encoding = face_recognition.face_encodings(known_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee1f1b29-43cd-40d0-b845-e9066bfa8466",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-20T08:53:22.139880Z",
     "iopub.status.busy": "2021-10-20T08:53:22.139880Z",
     "iopub.status.idle": "2021-10-20T08:53:22.147860Z",
     "shell.execute_reply": "2021-10-20T08:53:22.146862Z",
     "shell.execute_reply.started": "2021-10-20T08:53:22.139880Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "known_face_encoding != []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9739097f-3392-44eb-b467-becaa8071be3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-20T08:51:06.937944Z",
     "iopub.status.busy": "2021-10-20T08:51:06.936946Z",
     "iopub.status.idle": "2021-10-20T08:51:06.956893Z",
     "shell.execute_reply": "2021-10-20T08:51:06.956893Z",
     "shell.execute_reply.started": "2021-10-20T08:51:06.936946Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[182, 186, 187],\n",
       "       [182, 186, 187],\n",
       "       [182, 186, 187],\n",
       "       ...,\n",
       "       [ 95, 114,  95],\n",
       "       [ 99, 118,  98],\n",
       "       [101, 119,  97]], dtype=uint8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "known_img[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02cdb3b-08d8-41cb-8b02-1da310df9bfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68c3a7a6-7cc6-4889-9a10-c23ef4f1864e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T11:45:12.549370Z",
     "iopub.status.busy": "2021-10-21T11:45:12.549370Z",
     "iopub.status.idle": "2021-10-21T11:45:12.567331Z",
     "shell.execute_reply": "2021-10-21T11:45:12.566325Z",
     "shell.execute_reply.started": "2021-10-21T11:45:12.549370Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_alpha_channel(img):\n",
    "    \"\"\" 为jpg图像添加alpha通道 \"\"\"\n",
    " \n",
    "    b_channel, g_channel, r_channel = cv2.split(img) # 剥离jpg图像通道\n",
    "    alpha_channel = np.ones(b_channel.shape, dtype=b_channel.dtype) * 255 # 创建Alpha通道\n",
    " \n",
    "    img_new = cv2.merge((b_channel, g_channel, r_channel, alpha_channel)) # 融合通道\n",
    "    return img_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21fb15ab-94dc-4c7c-9c52-679ef4bee190",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T11:45:13.604306Z",
     "iopub.status.busy": "2021-10-21T11:45:13.604306Z",
     "iopub.status.idle": "2021-10-21T11:45:13.624247Z",
     "shell.execute_reply": "2021-10-21T11:45:13.623244Z",
     "shell.execute_reply.started": "2021-10-21T11:45:13.604306Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def merge_img(jpg_img, png_img, y1, y2, x1, x2):\n",
    "    \"\"\" 将png透明图像与jpg图像叠加 \n",
    "        y1,y2,x1,x2为叠加位置坐标值\n",
    "    \"\"\"\n",
    "    \n",
    "    # 判断jpg图像是否已经为4通道\n",
    "    if jpg_img.shape[2] == 3:\n",
    "        jpg_img = add_alpha_channel(jpg_img)\n",
    "    else:\n",
    "        raise Exception('jpg图像不为3通道')\n",
    "        \n",
    "    # 判断png图像是否已经为4通道\n",
    "    if png_img.shape[2] != 4:\n",
    "        raise Exception('png图像不为4通道')\n",
    "    \n",
    "    '''\n",
    "    当叠加图像时，可能因为叠加位置设置不当，导致png图像的边界超过背景jpg图像，而程序报错\n",
    "    这里设定一系列叠加位置的限制，可以满足png图像超出jpg图像范围时，依然可以正常叠加\n",
    "    '''\n",
    "    yy1 = 0\n",
    "    yy2 = png_img.shape[0]\n",
    "    xx1 = 0\n",
    "    xx2 = png_img.shape[1]\n",
    " \n",
    "    if x1 < 0:\n",
    "        xx1 = -x1\n",
    "        x1 = 0\n",
    "    if y1 < 0:\n",
    "        yy1 = - y1\n",
    "        y1 = 0\n",
    "    if x2 > jpg_img.shape[1]:\n",
    "        xx2 = png_img.shape[1] - (x2 - jpg_img.shape[1])\n",
    "        x2 = jpg_img.shape[1]\n",
    "    if y2 > jpg_img.shape[0]:\n",
    "        yy2 = png_img.shape[0] - (y2 - jpg_img.shape[0])\n",
    "        y2 = jpg_img.shape[0]\n",
    " \n",
    "    # 获取要覆盖图像的alpha值，将像素值除以255，使值保持在0-1之间\n",
    "    alpha_png = png_img[yy1:yy2,xx1:xx2,3] / 255.0\n",
    "    alpha_jpg = 1 - alpha_png\n",
    "    \n",
    "    # 开始叠加\n",
    "    for c in range(0,3):\n",
    "        jpg_img[y1:y2, x1:x2, c] = ((alpha_jpg*jpg_img[y1:y2,x1:x2,c]) + (alpha_png*png_img[yy1:yy2,xx1:xx2,c]))\n",
    "    # 4通道转换成3通道\n",
    "    jpg_img = jpg_img[:,:,:3]\n",
    " \n",
    "    return jpg_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1540607-5fc1-47b3-b06a-4c2970085270",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T11:45:37.181818Z",
     "iopub.status.busy": "2021-10-21T11:45:37.181818Z",
     "iopub.status.idle": "2021-10-21T11:46:53.253955Z",
     "shell.execute_reply": "2021-10-21T11:46:53.252958Z",
     "shell.execute_reply.started": "2021-10-21T11:45:37.181818Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['刘青沅.jpg', '宋佳乐.jpg', '张泰.jpg', '菅韧.jpg']\n",
      "0\n",
      "C:/Users/14640/Pictures/known_pictures/刘青沅.jpg\n",
      "刘青沅\n",
      "liu qing yuan\n",
      "1\n",
      "C:/Users/14640/Pictures/known_pictures/宋佳乐.jpg\n",
      "宋佳乐\n",
      "song jia le\n",
      "2\n",
      "C:/Users/14640/Pictures/known_pictures/张泰.jpg\n",
      "张泰\n",
      "zhang tai\n",
      "3\n",
      "C:/Users/14640/Pictures/known_pictures/菅韧.jpg\n",
      "菅韧\n",
      "jian ren\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pinyin.cedict\n",
    "\n",
    "# This is a super simple (but slow) example of running face recognition on live video from your webcam.\n",
    "# There's a second example that's a little more complicated but runs faster.\n",
    "\n",
    "# PLEASE NOTE: This example requires OpenCV (the `cv2` library) to be installed only to read from your webcam.\n",
    "# OpenCV is *not* required to use the face_recognition library. It's only required if you want to run this\n",
    "# specific demo. If you have trouble installing it, try any of the other demos that don't require it instead.\n",
    "\n",
    "# Get a reference to webcam #0 (the default one)\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "known_path = \"C:/Users/14640/Pictures/known_pictures/\"\n",
    "imgnames = os.listdir(known_path)\n",
    "print(imgnames)\n",
    "\n",
    "known_images = []\n",
    "known_face_encodings = []\n",
    "known_face_names = []\n",
    "\n",
    "for i in range(len(imgnames)):\n",
    "    print(i)\n",
    "    print(known_path+imgnames[i])\n",
    "    \n",
    "    # Load a sample picture and learn how to recognize it.\n",
    "    known_img = face_recognition.load_image_file(known_path+imgnames[i])\n",
    "    known_face_encoding = face_recognition.face_encodings(known_img)\n",
    "    \n",
    "    # 如果不能检测到脸\n",
    "    if known_face_encoding == []:\n",
    "        print(known_path+imgnames[i]+' ---->>> 没有检测到人脸')\n",
    "        \n",
    "    known_face_encodings.append(known_face_encoding[0])\n",
    "    known_images.append(known_img)\n",
    "    \n",
    "    # 获取成中文名\n",
    "    china_name = os.path.splitext(imgnames[i])[0]\n",
    "    print(china_name)\n",
    "    \n",
    "    # 获取拼音\n",
    "    pinyin_name = pinyin.get(china_name, format=\"strip\", delimiter=\" \")\n",
    "    print(pinyin_name)\n",
    "    \n",
    "    known_face_names.append(pinyin_name)\n",
    "    \n",
    "# # Load a second sample picture and learn how to recognize it.\n",
    "# biden_image = face_recognition.load_image_file(\"biden.jpg\")\n",
    "# biden_face_encoding = face_recognition.face_encodings(biden_image)[0]\n",
    "\n",
    "# Create arrays of known face encodings and their names\n",
    "# known_face_encodings\n",
    "\n",
    "# known_face_names = [\n",
    "# #     \"Joe Biden\"\n",
    "# ]\n",
    "\n",
    "while True:\n",
    "    # 边框(透明png)\n",
    "    bod = cv2.imread(r'C:\\Users\\14640\\Pictures\\bodimg\\ds.png',-1)\n",
    "    \n",
    "    # Grab a single frame of video\n",
    "    ret, frame = video_capture.read()\n",
    "    \n",
    "    fh,fw,fs = frame.shape\n",
    "\n",
    "    # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
    "    rgb_frame = frame[:, :, ::-1]\n",
    "\n",
    "    # Find all the faces and face enqcodings in the frame of video\n",
    "    face_locations = face_recognition.face_locations(rgb_frame, number_of_times_to_upsample=1, model='hog')\n",
    "    face_encodings = face_recognition.face_encodings(rgb_frame, face_locations, num_jitters=1, model='large')\n",
    "\n",
    "    # Loop through each face in this frame of video\n",
    "    for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "        # See if the face is a match for the known face(s)\n",
    "        matches = face_recognition.compare_faces(known_face_encodings, face_encoding, tolerance=0.4)\n",
    "\n",
    "        name = \"Unknown\"\n",
    "\n",
    "        # If a match was found in known_face_encodings, just use the first one.\n",
    "        # if True in matches:\n",
    "        #     first_match_index = matches.index(True)\n",
    "        #     name = known_face_names[first_match_index]\n",
    "\n",
    "        # Or instead, use the known face with the smallest distance to the new face\n",
    "        face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "        best_match_index = np.argmin(face_distances)\n",
    "        if matches[best_match_index]:\n",
    "            name = known_face_names[best_match_index]\n",
    "\n",
    "            \n",
    "        # Draw a box around the face\n",
    "#         cv2.rectangle(frame, (left, top), (right, bottom), (255, 255, 255), 2)\n",
    "        \n",
    "    \n",
    "        # 添加 png(bod边框)\n",
    "        if top-40 >= 0:\n",
    "            fac_t = top-40\n",
    "        else:\n",
    "            fac_t = 0\n",
    "        if bottom+10 <= fh:\n",
    "            fac_b = bottom+10\n",
    "        else:\n",
    "            fac_b = fh\n",
    "        if left-10 >= 0:\n",
    "            fac_l = left-10\n",
    "        else:\n",
    "            fac_l = 0\n",
    "        if right+10 <= fw:\n",
    "            fac_r = right+10\n",
    "        else:\n",
    "            fac_r = fw\n",
    "        fac = frame[fac_t: fac_b, fac_l: fac_r]  # 第top行到第bottom行，第left列到第right列\n",
    "        h,w,s=fac.shape\n",
    "        bod=cv2.resize(bod,(w,h),interpolation=cv2.INTER_LINEAR)#两图像补充为一样的大小\n",
    "        fac=merge_img(fac, bod, 0, h, 0, w)\n",
    "        frame[fac_t: fac_b, fac_l: fac_r] = fac\n",
    "\n",
    "        # Draw a label with a name below the face\n",
    "        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (255,255,255), 1)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, name, (left + int(w*0.15), bottom - int(h*0.1)), font, 0.5, (255,191,0), 1)\n",
    "        cv2.putText(frame, str(np.min(face_distances))[0:6], (left + int(w*0.2), bottom + int(h*0.1)), font, 0.5, (255,191,0), 1)\n",
    "\n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Hit 'q' on the keyboard to quit!\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release handle to the webcam\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "87f78480-ce2f-4f30-8e5a-8f54ffd41942",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-20T13:47:02.514068Z",
     "iopub.status.busy": "2021-10-20T13:47:02.514068Z",
     "iopub.status.idle": "2021-10-20T13:47:05.710134Z",
     "shell.execute_reply": "2021-10-20T13:47:05.709133Z",
     "shell.execute_reply.started": "2021-10-20T13:47:02.514068Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bod = cv2.imread(r'C:\\Users\\14640\\Pictures\\bodimg\\ds.png',-1)\n",
    "cv2.imshow('bod', bod)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b680b68-4ff4-4f48-8839-979c07d380e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7d41b7-856c-4138-9ed1-527a1a9bef14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbae220-38a3-4748-bc95-9ef078b0a3b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
